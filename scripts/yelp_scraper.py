import requests
import sqlite3
import os
import time
from urllib.parse import urlencode
from config import API_KEY, CITIES, CATEGORIES, RECORDS_PER_CATEGORY
from scripts.utils import get_location_id, get_category_id

# Yelp API ç›¸å…³ä¿¡æ¯
BASE_URL = "https://api.yelp.com/v3/businesses/search"
HEADERS = {"Authorization": f"Bearer {API_KEY}"}

# è·å–æ•°æ®åº“è·¯å¾„
DB_PATH = os.path.join(os.path.dirname(os.path.abspath(__file__)), "../data/yelp_restaurants.db")


def fetch_restaurants(city, category):
    """ ä» Yelp API è·å–æŒ‡å®šåŸå¸‚ & ç±»åˆ«çš„é¤å…æ•°æ® """
    restaurants = []
    offset = 0
    limit = 50  # Yelp API æ¯æ¬¡æœ€å¤šè¿”å› 50 æ¡æ•°æ®

    while offset < RECORDS_PER_CATEGORY:
        params = {
            "location": city,
            "categories": category,
            "limit": limit,
            "offset": offset,
        }
        url = f"{BASE_URL}?{urlencode(params)}"

        response = requests.get(url, headers=HEADERS)
        if response.status_code != 200:
            print(f"âš ï¸  è·å– {city} - {category} å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}")
            return []  # ç›´æ¥è¿”å›ç©ºåˆ—è¡¨

        data = response.json()
        businesses = data.get("businesses", [])
        restaurants.extend(businesses)

        if len(businesses) < limit:
            break  # å·²ç»è·å–å®Œæ‰€æœ‰æ•°æ®ï¼Œä¸éœ€è¦ç»§ç»­è¯·æ±‚ä¸‹ä¸€é¡µ

        offset += limit
        time.sleep(1)  # é¿å… API é€Ÿç‡é™åˆ¶

    return restaurants


def save_to_database(restaurants, city):
    """ å°†çˆ¬å–çš„é¤å…æ•°æ®å­˜å…¥ SQLite æ•°æ®åº“ """
    conn = sqlite3.connect(DB_PATH)
    cursor = conn.cursor()

    for rest in restaurants:
        name = rest["name"]
        rating = rest.get("rating", 0)
        price = rest.get("price", "N/A")
        address = ", ".join(rest["location"].get("display_address", []))
        latitude = rest["coordinates"].get("latitude")
        longitude = rest["coordinates"].get("longitude")

        # è·å–æˆ–åˆ›å»º location_id
        location_id = get_location_id(cursor, city, address, latitude, longitude)

        # è·å–æˆ–åˆ›å»º category_id
        category_id = get_category_id(cursor, rest["categories"])

        # ç”Ÿæˆå”¯ä¸€ restaurant_id
        restaurant_id = f"{city[:3].upper()}{str(hash(name))[:6]}"

        cursor.execute("""
        INSERT OR IGNORE INTO restaurants (restaurant_id, name, rating, price, category_id, location_id)
        VALUES (?, ?, ?, ?, ?, ?)
        """, (restaurant_id, name, rating, price, category_id, location_id))

    conn.commit()
    conn.close()


def run_scraper():
    """ ä¸»å‡½æ•°ï¼šéå†åŸå¸‚ & ç±»åˆ«ï¼Œçˆ¬å– Yelp æ•°æ® """
    for city in CITIES:
        for category in CATEGORIES:
            print(f"ğŸ“¡ çˆ¬å– {city} - {category} æ•°æ®ä¸­...")
            restaurants = fetch_restaurants(city, category)

            # å¦‚æœè¯¥ç±»åˆ«çš„é¤å…æ•°é‡ä¸è¶³ 150ï¼Œä»ç„¶ä¿å­˜å·²æœ‰çš„æ•°æ®
            if len(restaurants) < RECORDS_PER_CATEGORY:
                print(
                    f"âš ï¸ {city} - {category} çš„é¤å…ä¸è¶³ {RECORDS_PER_CATEGORY} ä¸ªï¼ˆä»…æ‰¾åˆ° {len(restaurants)} ä¸ªï¼‰ï¼Œä¿å­˜å·²æœ‰æ•°æ®å¹¶ç»§ç»­ã€‚")
                if restaurants:  # å¦‚æœæœ‰æ•°æ®ï¼Œåˆ™ä¿å­˜
                    save_to_database(restaurants, city)
                    print(f"âœ… {len(restaurants)} æ¡æ•°æ®å­˜å…¥æ•°æ®åº“")
                continue  # ç»§ç»­åˆ°ä¸‹ä¸€ä¸ªç±»åˆ«

            # å¦‚æœé¤å…æ•°é‡è¶³å¤Ÿï¼Œç›´æ¥ä¿å­˜
            save_to_database(restaurants, city)
            print(f"âœ… {len(restaurants)} æ¡æ•°æ®å­˜å…¥æ•°æ®åº“")

    print("ğŸ‰ çˆ¬å–ä»»åŠ¡å®Œæˆï¼")